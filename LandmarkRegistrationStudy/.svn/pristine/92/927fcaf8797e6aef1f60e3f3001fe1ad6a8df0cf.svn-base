import os
import unittest
import vtk, qt, ctk, slicer
from slicer.ScriptedLoadableModule import *
import logging
import numpy as np

#
# PreProcessLandmarks
#

class PreProcessLandmarks(ScriptedLoadableModule):
  """Uses ScriptedLoadableModule base class, available at:
  https://github.com/Slicer/Slicer/blob/master/Base/Python/slicer/ScriptedLoadableModule.py
  """

  def __init__(self, parent):
    ScriptedLoadableModule.__init__(self, parent)
    self.parent.title = "PreProcessLandmarks" # TODO make this more human readable by adding spaces
    self.parent.categories = ["Scoliosis"]
    self.parent.dependencies = []
    self.parent.contributors = ["Ben Church - Queen's University, PerkLab"]
    self.parent.helpText = """
    This module can be used to extrapolate or interpolate incomplete scans of the
    transverse processes"""
    self.parent.acknowledgementText = """ """ # replace with organization, grant and thanks.

#
# PreProcessLandmarksWidget
#

class PreProcessLandmarksWidget(ScriptedLoadableModuleWidget):
  """Uses ScriptedLoadableModuleWidget base class, available at:
  https://github.com/Slicer/Slicer/blob/master/Base/Python/slicer/ScriptedLoadableModule.py
  """

  def setup(self):
    ScriptedLoadableModuleWidget.setup(self)

    # Instantiate and connect widgets ...

    # User interface for incomplete landmark set repair
    RepairInterface = ctk.ctkCollapsibleButton()
    RepairInterface.text = "Markups node repair"
    self.layout.addWidget(RepairInterface)
    RepairInterfaceLayout = qt.QFormLayout(RepairInterface)
    #RepairInterfaceLayout.collapsed = True
    
    # Dropdown list to select MarkupsNode for repair
    self.RepairNodeSelector = slicer.qMRMLNodeComboBox()
    self.RepairNodeSelector.nodeTypes = ["vtkMRMLMarkupsFiducialNode",]
    self.RepairNodeSelector.selectNodeUponCreation = True
    self.RepairNodeSelector.enabled  = True
    self.RepairNodeSelector.addEnabled = True
    self.RepairNodeSelector.noneEnabled = False
    self.RepairNodeSelector.removeEnabled = True
    self.RepairNodeSelector.renameEnabled = True
    self.RepairNodeSelector.toolTip = "Choose the incomplete landmarks node to be repaired to completion"
    RepairInterfaceLayout.addRow("Node to repair:", self.RepairNodeSelector)
    self.RepairNodeSelector.setMRMLScene(slicer.mrmlScene)
    
    self.RepairNodeButton = qt.QPushButton("Repair landmarks node")
    self.RepairNodeButton.toolTip = "Currently seperates right from left sided points"
    RepairInterfaceLayout.addRow(self.RepairNodeButton)
    
    # Button connections
    self.RepairNodeButton.connect('clicked(bool)', self.OnRepairButtonClicked)

    # Reload module button
    self.reloadButton = qt.QPushButton('Reload module')
    RepairInterfaceLayout.addRow(self.reloadButton)

    # connections
    self.reloadButton.connect('clicked(bool)', self.OnReloadButton)
    
    # Add vertical spacer
    self.layout.addStretch(1)

  def cleanup(self):
    pass

  def OnRepairButtonClicked(self):
    logic = PreProcessLandmarksLogic(self.RepairNodeSelector.currentNode())
    logic.RepairNode()

  def OnReloadButton(self):
    slicer.util.reloadScriptedModule(slicer.moduleNames.PreProcessLandmarks)
    
#
# PreProcessLandmarksLogic
#

class PreProcessLandmarksLogic(ScriptedLoadableModuleLogic):
  def __init__(self, Markups):
    self.MarkupsNode = Markups
    self.LeftMarkupsNode = slicer.vtkMRMLMarkupsFiducialNode()
    self.RightMarkupsNode = slicer.vtkMRMLMarkupsFiducialNode()
    self.LeftMarkupsNode.SetName(self.MarkupsNode.GetName() + 'Left')
    self.RightMarkupsNode.SetName(self.MarkupsNode.GetName() + 'Right')

    self.OriginalPoints = []
    for i in range(Markups.GetNumberOfFiducials()):
      self.OriginalPoints.append((Markups.GetNthFiducialLabel(i), Markups.GetMarkupPointVector(i,0)))
    self.OriginalLabels = [i[0] for i in self.OriginalPoints]
    self.OriginalCoords = [i[1] for i in self.OriginalPoints]

  def SortPointsVertically(self):
    self.VerticallySortedPoints = sorted(self.OriginalPoints, key=lambda LabelCoords: LabelCoords[1][2])
    self.VerticallySortedPoints.reverse()
    #print self.VerticallySortedPoints

  def AnisotrpoicNormalization(self, PointSet):
    # Start by finding top and bottom points of spine for verticle normalization
    SetLeft = 10000
    SetRight = -10000
    SetFront = -10000
    SetBack = 10000
    SetTop = -10000
    SetBottom = 10000

    for Point in PointSet:
      Coords  = Point[1]
      if Coords[0] < SetLeft:
        SetLeft = Coords[0]
      if Coords[0] > SetRight:
        SetRight = Coords[0]
      if Coords[1] < SetBack:
        SetBack = Coords[1]
      if Coords[1] > SetFront:
        SetFront = Coords[1]
      if Coords[2] > SetTop:
        SetTop = Coords[2]
      if Coords[2] < SetBottom:
        SetBottom = Coords[2]
      
    SetHeight = SetTop - SetBottom
    SetWidth = SetRight - SetLeft
    SetDepth = SetFront - SetBack
    
    # (Re) initialize normalized point list
    NormalizedPoints = len(PointSet) * [0]
    
    # Normalize S-I dimension to R-L scale
    for i, Point in enumerate(PointSet):
      Coords = Point[1]
      NormalizedPoints[i] = np.array([Coords[0], (Coords[1]) * (SetWidth / (SetDepth * 3.0)), (Coords[2]) * (SetWidth / (SetHeight * 2.0))])
    return NormalizedPoints
  
  def ShouldStopKMeans(self, oldCentroids, Centroids, iterations):
    MaxIterations = 500
    StoppingDelta = 0.05
    #print oldCentroids, Centroids
    if iterations > MaxIterations: return True
    if iterations == 0:
      return False
    for C in range(len(oldCentroids)):
      #print oldCentroids[C], Centroids[C]
      if np.linalg.norm(oldCentroids[C] - Centroids[C]) < StoppingDelta:
        return True
    return False

  def GetKMeansLabels(self, DataSet, Centroids, Labels):
    for i, Coords in enumerate(DataSet):
      #PointCentroidDistance = np.linalg.norm(Coords - Centroids[0])
      minDist = 1000000
      Labels[i] = 0
      for j, CentroidVector in enumerate(Centroids):
        #print Coords, CentroidVector#, np.linalg.norm(Coords - CentroidVector)
        PointCentroidDistance = np.linalg.norm(Coords - CentroidVector)
        if PointCentroidDistance < minDist:
          minDist = PointCentroidDistance
          Labels[i] = j
    return Labels

  def GetCentroids(self, DataSet, Labels, k):
    Centroids = []
    #print Labels
    for C in range(k):    # For each centroid
      Centroid = np.random.uniform() * np.ones(len(DataSet[0]))    # Each centroid with as many dimensions as the data
      
      for i, Coords in enumerate(DataSet): # Take each data point contributing to the centroid into consideration
        if Labels[i] == C:                    # if it belongs to the current centroid
          for dim in range(len(Centroid)):
            Centroid[dim] += Coords[dim]
            
      for dim in range(len(Centroid)):
        Centroid[dim] = Centroid[dim] / np.count_nonzero(Labels == C)
      Centroids.append(Centroid)
    return Centroids

  def KMeans(self, DataSet, k=2):   # Expects DataSet as list of (Label, np.array[R,A,S]) tuples, uses k=2 by default for left and right sides
    DataSetLabels = np.zeros(len(DataSet))
    for i in range(len(DataSetLabels)):
      DataSetLabels[i] = int(round(np.random.uniform()))
    # Initialize centroids
    numFeatures = len(DataSet[0])
    Centroids = k * [0]
    # Try initializing one centroid on each side
    Centroids[0] = np.array([min([i[0] for i in DataSet]),0,0])
    Centroids[1] = np.array([max([i[0] for i in DataSet]),0,0])
    
  # Initialize book keeping variables
    iterations = 0
    oldCentroids = k * [0]
    for Cent in range(k):
      oldCentroids[Cent] = np.array(numFeatures * [np.random.uniform()])

    # Run the k-means algorithm
    while not self.ShouldStopKMeans(oldCentroids, Centroids, iterations):
      oldCentroids = Centroids
      iterations += 1
      
      DataSetLabels = self.GetKMeansLabels(DataSet, Centroids, DataSetLabels)
      Centroids = self.GetCentroids(DataSet, DataSetLabels, k)
      #print Centroids
    return (DataSetLabels, Centroids)
    
  def ClassifyLeftRight(self):
    self.SortPointsVertically()
    SortedPointsLeftVotes = len(self.VerticallySortedPoints) * [0]
    SortedPointsRightVotes = len(self.VerticallySortedPoints) * [0]
    for i in range(0, len(self.VerticallySortedPoints)-5):
      #Sextuple = [np.array(k[1]) for k in self.VerticallySortedPoints[i:i+6]]
      Sextuple = self.VerticallySortedPoints[i:i+6]
      #print Sextuple
      NormalizedSextuple = self.AnisotrpoicNormalization(Sextuple)
      (KmLabels, KmCentroids) = self.KMeans(NormalizedSextuple, 2)

      # If KmLabel == 0 indicates a left-side point
      if KmCentroids[0][0] < KmCentroids[1][0]:
        for j, Label in enumerate(KmLabels):
          if Label == 0:
            SortedPointsLeftVotes[i + j] = SortedPointsLeftVotes[i + j] + 1
          else:
            SortedPointsRightVotes[i + j] = SortedPointsRightVotes[i + j] + 1
      else: # If KmLabel == 0 indicates a right-side point
        for j, Label in enumerate(KmLabels):
          #print i, j
          if Label == 0:
            SortedPointsRightVotes[i + j] = SortedPointsRightVotes[i + j] + 1
          else:
            SortedPointsLeftVotes[i + j] = SortedPointsLeftVotes[i + j] + 1

    self.LeftMarkupsNode.RemoveAllMarkups()
    self.RightMarkupsNode.RemoveAllMarkups()
    
    for i, UnclassifiedPoint in enumerate(self.VerticallySortedPoints):
      OriginalPointIndex = self.OriginalLabels.index(UnclassifiedPoint[0])
      OriginalPoint = self.OriginalCoords[OriginalPointIndex]
      if SortedPointsLeftVotes[i] > SortedPointsRightVotes[i]:
        self.LeftMarkupsNode.AddFiducialFromArray(OriginalPoint)
        self.LeftMarkupsNode.SetNthFiducialLabel(self.LeftMarkupsNode.GetNumberOfFiducials()-1, self.VerticallySortedPoints[i][0] + '_Left')
      else:
        self.RightMarkupsNode.AddFiducialFromArray(OriginalPoint)
        self.RightMarkupsNode.SetNthFiducialLabel(self.RightMarkupsNode.GetNumberOfFiducials()-1, self.VerticallySortedPoints[i][0] + '_Right')

    if slicer.util.getNode(self.LeftMarkupsNode.GetName()) != None:
      slicer.mrmlScene.RemoveNode(slicer.util.getNode(self.LeftMarkupsNode.GetName()))
    if slicer.util.getNode(self.RightMarkupsNode.GetName()) != None:
      slicer.mrmlScene.RemoveNode(slicer.util.getNode(self.RightMarkupsNode.GetName()))
      
    slicer.mrmlScene.AddNode(self.LeftMarkupsNode)
    slicer.mrmlScene.AddNode(self.RightMarkupsNode)
    
  def PolyFit(self, Node, Plot=False):    # Meant to fit polynomial to right or left sideed landmarks, returns polynomial coefficients
    PointsPerCurve = 500
    Coords = [Node.GetMarkupPointVector(i,0) for i in range(Node.GetNumberOfFiducials())]
    R = [Coords[i][0] for i in range(len(Coords))]
    A = [Coords[i][1] for i in range(len(Coords))]
    S = [Coords[i][2] for i in range(len(Coords))]
    
    sSpace = np.linspace(S[0], S[-1], PointsPerCurve)

    S_R_FitCoefs = np.polyfit(S, R, 5)
    S_A_FitCoefs = np.polyfit(S, A, 4)
    
    SrPolynomial = np.poly1d(S_R_FitCoefs)
    SaPolynomial = np.poly1d(S_A_FitCoefs)
    
    #print "SR fit:", SrPolynomial
    #print "SA fit:", SaPolynomial
    
    if Plot:
      OldCharts = slicer.mrmlScene.GetNodesByClass('vtkMRMLChartNode')
      while OldCharts.GetItemAsObject(0) != None:
        slicer.mrmlScene.RemoveNode(OldCharts.GetItemAsObject(0))
        OldCharts = slicer.mrmlScene.GetNodesByClass('vtkMRMLChartNode')
    
      OldArrays = slicer.mrmlScene.GetNodesByClass('vtkMRMLDoubleArrayNode')
      while OldArrays.GetItemAsObject(0) != None:
        slicer.mrmlScene.RemoveNode(OldArrays.GetItemAsObject(0))
        OldArrays = slicer.mrmlScene.GetNodesByClass('vtkMRMLDoubleArrayNode')
        
      
      aDomainNode = slicer.mrmlScene.AddNode(slicer.vtkMRMLDoubleArrayNode())
      #aDomain = aDomainNode.GetArray()
      #aDomain.SetNumberOfTuples(PointsPerCurve)
      #aDomain.SetNumberOfComponents(2)
      for i, s in enumerate(sSpace):
        aDomainNode.AddXYValue(s, SaPolynomial(s), 0)
        #aDomain.SetComponent(i, 0, s)
        #aDomain.SetComponent(i, 1, SaPolynomial(s))
        #aDomain.SetComponent(i, 2, 0)
      
      aPointsNode = slicer.mrmlScene.AddNode(slicer.vtkMRMLDoubleArrayNode())
      #aPointsArray = aPointsNode.GetArray()
      #aPointsArray.SetNumberOfTuples(len(A))
      #aPointsArray.SetNumberOfComponents(2)
      for i, (a, s) in enumerate(zip(A,S)):
        aPointsNode.AddXYValue(s, a, 0)
        #aPointsArray.SetComponent(i, 0, s)
        #aPointsArray.SetComponent(i, 1, a)
        #aPointsArray.SetComponent(i, 2, 0)
      
      # Creates chart view
      lns = slicer.mrmlScene.GetNodesByClass('vtkMRMLLayoutNode')
      lns.InitTraversal()
      ln = lns.GetNextItemAsObject()
      ln.SetViewArrangement(24)
      
      # Get chart view node
      cvns = slicer.mrmlScene.GetNodesByClass('vtkMRMLChartViewNode')
      cvns.InitTraversal()
      cvn = cvns.GetNextItemAsObject()
      
      # Create chart node
      cna = slicer.mrmlScene.AddNode(slicer.vtkMRMLChartNode())
      
      cna.AddArray('S-A Polyfit', aDomainNode.GetID())
      cna.AddArray('S-A Data', aPointsNode.GetID())

      # Setting properties on the chart
      cna.SetProperty('default', 'title', Node.GetName() + ' A-P')
      cna.SetProperty('default', 'xAxisLabel', 'S-I')
      cna.SetProperty('default', 'yAxisLabel', 'A-P')
      
      # Which chart to display
      cvn.SetChartNodeID(cna.GetID())
      
      """
      #Create chart node
      cnr = slicer.mrmlScene.AddNode(slicer.vtkMRMLChartNode())
      
      rSpace = np.linspace(S[0], S[-1], PointsPerCurve)
      rDomainNode = slicer.mrmlScene.AddNode(slicer.vtkMRMLDoubleArrayNode())
      rDomain = rDomainNode.GetArray()
      rDomain.SetNumberOfTuples(PointsPerCurve)
      rDomain.SetNumberOfComponents(2)
      for i, s in enumerate(sSpace):
        rDomain.SetComponent(i, 0, s)
        rDomain.SetComponent(i, 1, SrPolynomial(s))
        
      rPointsNode = slicer.mrmlScene.AddNode(slicer.vtkMRMLDoubleArrayNode())
      rPointsArray = rPointsNode.GetArray()
      rPointsArray.SetNumberOfTuples(len(R))
      rPointsArray.SetNumberOfComponents(2)
      for i, (r, s) in enumerate(zip(R,S)):
        rPointsArray.SetComponent(i, 0, s)
        rPointsArray.SetComponent(i, 1, r)
      
      #lns.InitTraversal()
      #ln = lns.GetNextItemAsObject()
      #ln.SetViewArrangement(24)
      #cvns.InitTraversal()
      #cvn = cvns.GetNextItemAsObject()
      
      cnr.AddArray('S-R Polyfit', rDomainNode.GetID())
      cnr.AddArray('S-R Data', rPointsNode.GetID())

      #Setting properties on the chart
      cnr.SetProperty('default', 'title', Node.GetName() + ' R-L')
      cnr.SetProperty('default', 'xAxisLabel', 'S-I')
      cnr.SetProperty('default', 'yAxisLabel', 'R-L')
      
      #Which chart to display
      cvn.SetChartNodeID(cnr.GetID())
      """
      
    return (SrPolynomial, SaPolynomial)
   
  def GetCurvewiseInterpointDistances(self, Node, (SrPolynomial, SaPolynomial)):
    PointsPerCurve = 500
    Coords = [Node.GetMarkupPointVector(i,0) for i in range(Node.GetNumberOfFiducials())]
    R = [Coords[i][0] for i in range(len(Coords))]
    A = [Coords[i][1] for i in range(len(Coords))]
    S = [Coords[i][2] for i in range(len(Coords))]
    sSpace = np.linspace(S[0], S[-1], PointsPerCurve)
   
    # Distances along the polynomial to each landmark in the given dimension
    PointDistances = []
    #priorS = sSpace[0]
    sIndex = 1
    
    # Find points in sSpace corresponding to landmarks in both R and A dimension
    CurveDistance = 0
    for i, Landmark in enumerate(zip(R[:-1],A[:-1])):
      CurrentIntervalLength = 0
      while sSpace[sIndex] > S[i+1]:
        PriorS = sSpace[sIndex-1]
        CurrentS = sSpace[sIndex]
        PriorR = SrPolynomial(PriorS)
        CurrentR = SrPolynomial(CurrentS)
        PriorA = SaPolynomial(PriorS)
        CurrentA = SaPolynomial(CurrentS)
        CurveIncrementDistance = np.sqrt(((CurrentS- PriorS)**2) + ((CurrentR - PriorR)**2) + ((CurrentA - PriorA)**2)) 
        CurrentIntervalLength += CurveIncrementDistance
        CurveDistance += CurveIncrementDistance
        sIndex += 1
      PointDistances.append((CurveDistance, CurrentIntervalLength))
        
    return PointDistances
   
  def EstimateMissingPoints(self, PointDistances):
    # Estimates the number of missing points per suspiciously long interval
    MissingPointPredictions = np.zeros(len(PointDistances))
    MeanInterpointDistance = np.mean(PointDistances)
    PointDistanceStd = np.std(PointDistances)
    CandidateDistances = PointDistances
   
    # Rest of distance checking uses a lst good distance value; top of spine boundary we don't have one yet
    if PointDistances[0] > MeanInterpointDistance + np.std(PointDistances):   # Top inter-point distance is usually small, being thoracic versus lumbar
      # This condition indicates missing points at the top of the spine
      SuspiciousDistance = PointDistances[0]
      MissingPointsThisInterval = 1
      SubIntervalDistance = SuspiciousDistance / float(MissingPointsThisInterval + 1.0)
      CandidateDistances = np.delete(PointDistances, [0])
      CandidateDistances = np.insert(CandidateDistances, 0, (MissingPointsThisInterval + 1) * [SubIntervalDistance])
      MeanCandidateDistances = np.mean(CandidateDistances)

      # Check how many points should be added to produce intervals of typical length
      while SubIntervalDistance > MeanCandidateDistances:   # The sub interval distances seem to long, given the new average, for just one point to be missing
        MissingPointsThisInterval += 1
        SubIntervalDistance = SuspiciousDistance / float(MissingPointsThisInterval + 1.0)
        CandidateDistances = np.delete(PointDistances, [0])
        CandidateDistances = np.insert(CandidateDistances, 0, (MissingPointsThisInterval + 1) * [SubIntervalDistance])
        MeanCandidateDistances = np.mean(CandidateDistances)
      MissingPointPredictions[0] = MissingPointsThisInterval
    
    # ASSERT we are at the first apparently uninterrupted interval
      
    i = 1
    PriorGoodDistance = CandidateDistances[0]   # First interval in CandidateDistances is either repaired from above boundary treatment, or never needed repair
    while i < len(CandidateDistances)-1:
      MissingPointsThisInterval = 0
      if CandidateDistances[i] > 1.33 * PriorGoodDistance and CandidateDistances[i] > 1.33 * CandidateDistances[i+1]:
        SuspiciousDistance = CandidateDistances[i]
        MissingPointsThisInterval = 1
        SubIntervalDistance = SuspiciousDistance / float(MissingPointsThisInterval + 1.0)
        CandidateDistances = np.delete(PointDistances, [i - (len(CandidateDistances) - len(MissingPointPredictions))])
        CandidateDistances = np.insert(CandidateDistances, i, (MissingPointsThisInterval + 1) * [SubIntervalDistance])
        MeanCandidateDistances = np.mean(CandidateDistances)

        # Check how many points should be added to produce intervals of typical length
        while SubIntervalDistance > (1.33 * PriorGoodDistance) + 0.0*np.std(CandidateDistances) :   # The sub interval distances seem to long, given the new average, for just one point to be missing
          MissingPointsThisInterval += 1
          SubIntervalDistance = SuspiciousDistance / float(MissingPointsThisInterval + 1.0)
          CandidateDistances = np.delete(PointDistances, [i - (len(CandidateDistances) - len(MissingPointPredictions))])
          CandidateDistances = np.insert(CandidateDistances, i, (MissingPointsThisInterval + 1) * [SubIntervalDistance])
          MeanCandidateDistances = np.mean(CandidateDistances)
        MissingPointPredictions[i - (sum(MissingPointPredictions))] = MissingPointsThisInterval
      else:
        PriorGoodDistance = CandidateDistances[i]
      i += 1 + MissingPointsThisInterval
   
    if PointDistances[-1] > 1.33*PriorGoodDistance:
      # This condition indicates missing points at the bottom of the spine
      SuspiciousDistance = PointDistances[-1]
      MissingPointsThisInterval = 1
      SubIntervalDistance = SuspiciousDistance / float(MissingPointsThisInterval + 1.0)
      CandidateDistances = np.delete(PointDistances, [len(PointDistances)-1])
      CandidateDistances = np.insert(CandidateDistances, -1, (MissingPointsThisInterval + 1) * [SubIntervalDistance])
      MeanCandidateDistances = np.mean(CandidateDistances)

      # Check how many points should be added to produce intervals of typical length
      while SubIntervalDistance > MeanCandidateDistances - 0.25*np.std(CandidateDistances):   # The sub interval distances seem to long, given the new average, for just one point to be missing
        MissingPointsThisInterval += 1
        SubIntervalDistance = SuspiciousDistance / float(MissingPointsThisInterval + 1.0)
        CandidateDistances = np.delete(PointDistances, [len(PointDistances)-1])
        CandidateDistances = np.insert(CandidateDistances, -1, (MissingPointsThisInterval + 1) * [SubIntervalDistance])
        MeanCandidateDistances = np.mean(CandidateDistances)
      MissingPointPredictions[-1] = MissingPointsThisInterval
    return MissingPointPredictions
   
  def CompleteNodeFromPredictions(self, Node, CurvewiseDistances, MissingPointPredictions, (SrPolynomial, SaPolynomial)):
    PointsPerCurve = 500
    Coords = [Node.GetMarkupPointVector(i,0) for i in range(Node.GetNumberOfFiducials())]
    R = [Coords[i][0] for i in range(len(Coords))]
    A = [Coords[i][1] for i in range(len(Coords))]
    S = [Coords[i][2] for i in range(len(Coords))]
    sSpace = np.linspace(S[0], S[-1], PointsPerCurve)
    
    for i, Interval in enumerate(CurvewiseDistances):
      MissingPointsRemaining = MissingPointPredictions[i]
       
      if MissingPointsRemaining > 0:
        PointInsertionOffset = Interval / float(MissingPointsRemaining + 1.0)
        # Find beginning of current interval we wish to fill in
        sIndex = 1
        PriorS = sSpace[sIndex-1]
        CurrentS = sSpace[sIndex]
   
        # Find the beginning of the interval missing a point  (>= because we start at the top of thoracic and count down into lumbar)
        while CurrentS >= S[i]:
          PriorS = sSpace[sIndex-1]
          CurrentS = sSpace[sIndex]
          sIndex += 1
        
        NumImputations = 0
        DistanceOffset = 0            # Polynomila fit curve-wise distance from last point before broken interval
        while MissingPointsRemaining > 0:
          while DistanceOffset < PointInsertionOffset * float(NumImputations + 1):
            PriorS = sSpace[sIndex-1]
            CurrentS = sSpace[sIndex]
            PriorR = SrPolynomial(PriorS)
            CurrentR = SrPolynomial(CurrentS)
            PriorA = SaPolynomial(PriorS)
            CurrentA = SaPolynomial(CurrentS)
            DistanceOffset += np.sqrt(((CurrentS - PriorS)**2) + ((CurrentR - PriorR)**2) + ((CurrentA - PriorA)**2))
            sIndex += 1
          Coords = [CurrentR, CurrentA, CurrentS]
          Node.AddFiducialFromArray(Coords)
          NumImputations += 1
          MissingPointsRemaining -= 1
          
  def CurvewiseFrequencyAnalysis(self, Node, (SrPolynomial, SaPolynomial), Plot=False):
    PointsPerCurve = 500
    Coords = [Node.GetMarkupPointVector(i,0) for i in range(Node.GetNumberOfFiducials())]
    R = [Coords[i][0] for i in range(len(Coords))]
    A = [Coords[i][1] for i in range(len(Coords))]
    S = [Coords[i][2] for i in range(len(Coords))]
    sSpace = np.linspace(S[0], S[-1], PointsPerCurve)
    
    IntervalData = self.GetCurvewiseInterpointDistances(Node, (SrPolynomial, SaPolynomial))
    IntervalDistances = [IntervalData[i][1] for i in range(len(IntervalData))]
    
    # Try fitting polynomial to relationship between total distance travelled down the spine to the inter-landmark distances
    CumulativeDistance = 0
    CumulativeCurveDistances = []
    for i, Interval in enumerate(IntervalDistances):
      CumulativeCurveDistances.append(CumulativeDistance + (Interval/2.0))
      CumulativeDistance += Interval
    
    CurveSpace = np.linspace(0, CumulativeDistance, PointsPerCurve)
    FrequencyCoeffs = np.polyfit(CumulativeCurveDistances, IntervalDistances, 2)
    FrequencyPolynomial = np.poly1d(FrequencyCoeffs)
    
    MaxPolynomialError = 0
    MaxErrorLocation = 0
    AllIntervalErrors = []
    for i, Interval in enumerate(IntervalDistances):
      CurveDistanceFraction = CumulativeCurveDistances[i] / max(CurveSpace)
      CurveSpaceIndex = int(CurveDistanceFraction * (len(CurveSpace))-1)
      CurrentIntervalPolynomailError = FrequencyPolynomial(CurveSpace[CurveSpaceIndex]) - Interval
      AllIntervalErrors.append(CurrentIntervalPolynomailError)
      #print "Polynomial error for interval " + str(i) + ": ", CurrentIntervalPolynomailError, " at curve distance = ", CurveSpace[CurveSpaceIndex]
      if abs(CurrentIntervalPolynomailError) > abs(MaxPolynomialError):
        MaxPolynomialError = CurrentIntervalPolynomailError
        MaxErrorLocation = CurveSpace[CurveSpaceIndex]
        
    #print AllIntervalErrors
    #print "Max deviation: ", MaxPolynomialError, " at curveDistance = ", MaxErrorLocation
    
    if Plot:
      OldCharts = slicer.mrmlScene.GetNodesByClass('vtkMRMLChartNode')
      while OldCharts.GetItemAsObject(0) != None:
        slicer.mrmlScene.RemoveNode(OldCharts.GetItemAsObject(0))
        OldCharts = slicer.mrmlScene.GetNodesByClass('vtkMRMLChartNode')
    
      OldArrays = slicer.mrmlScene.GetNodesByClass('vtkMRMLDoubleArrayNode')
      while OldArrays.GetItemAsObject(0) != None:
        slicer.mrmlScene.RemoveNode(OldArrays.GetItemAsObject(0))
        OldArrays = slicer.mrmlScene.GetNodesByClass('vtkMRMLDoubleArrayNode')
     
      # Array for the polynomial fit to the interval distances
      CurveDomainNode = slicer.mrmlScene.AddNode(slicer.vtkMRMLDoubleArrayNode())
      for c in CurveSpace:
        CurveDomainNode.AddXYValue(c, FrequencyPolynomial(c), 0)
        
      # Array for the original interval distances
      DistancePointsNode = slicer.mrmlScene.AddNode(slicer.vtkMRMLDoubleArrayNode())
      for (ID, CD) in (zip(IntervalDistances, CumulativeCurveDistances)):
        DistancePointsNode.AddXYValue(CD, ID, 0)
        
      # Creates chart view
      lns = slicer.mrmlScene.GetNodesByClass('vtkMRMLLayoutNode')
      lns.InitTraversal()
      ln = lns.GetNextItemAsObject()
      ln.SetViewArrangement(24)
      
      # Create chart node
      ChartNode = slicer.mrmlScene.AddNode(slicer.vtkMRMLChartNode())

      # Get chart view node
      ChartViewNodes = slicer.mrmlScene.GetNodesByClass('vtkMRMLChartViewNode')
      ChartViewNodes.InitTraversal()
      ChartViewNode = ChartViewNodes.GetNextItemAsObject()
      
      ChartNode.AddArray('Interval Polyfit', CurveDomainNode.GetID())
      ChartNode.AddArray('Interval Distance Data', DistancePointsNode.GetID())

      # Setting properties on the chart
      ChartNode.SetProperty('default', 'title', Node.GetName() + 'Curve interval distances')
      ChartNode.SetProperty('default', 'xAxisLabel', 'Curve-wise distance from spine top')
      ChartNode.SetProperty('default', 'yAxisLabel', 'Interval length')
      
      # Which chart to display
      ChartViewNode.SetChartNodeID(ChartNode.GetID())
    
    print " "     # Empty line
    print Node.GetName(), ' IntervalDistances: ', IntervalDistances
    print Node.GetName(), " interval fit errors: ", AllIntervalErrors
    print "Max abs fit error (", str(MaxPolynomialError), ") to interval stddev (", str(np.std(IntervalDistances)), "): ", MaxPolynomialError / np.std(IntervalDistances)
    return (IntervalData, FrequencyPolynomial, AllIntervalErrors)
    
    MissingPointPredictions = self.EstimateMissingPoints(IntervalDistances)

    self.CompleteNodeFromPredictions(Node, IntervalDistances, MissingPointPredictions, (SrPolynomial, SaPolynomial))
    
    #print Node.GetName(), ' OmissionPredictions: ', MissingPointPredictions
    print ""
    
    """
    for i, IntervalPrediction in enumerate(MissingPointPredictions):
      if IntervalPrediction == 1:     # Interval is missing a point between Landmark[i] and Landmark[i+1]
        sIndex = 1
        PriorS = sSpace[sIndex-1]
        CurrentS = sSpace[sIndex]
        
        # Find the beginning of the interval missing a point  (>= because we start at the top of thoracic and count down into lumbar)
        while CurrentS >= S[i]:
          PriorS = sSpace[sIndex-1]
          CurrentS = sSpace[sIndex]
          sIndex += 1
        # ASSERT PriorS == S[i]; PriorS is at beginning of interval, and CurrentS is one poitn past, ready to start measuring distance
        
        DistanceGuess = IntervalDistances[i] / 2.0
        
        DistanceOffset = 0            # Polynomila fit curve-wise distance from last point before broken interval
        while DistanceOffset < DistanceGuess:
          PriorS = sSpace[sIndex-1]
          CurrentS = sSpace[sIndex]
          PriorR = SrPolynomial(PriorS)
          CurrentR = SrPolynomial(CurrentS)
          PriorA = SaPolynomial(PriorS)
          CurrentA = SaPolynomial(CurrentS)
          DistanceOffset += np.sqrt(((CurrentS - PriorS)**2) + ((CurrentR - PriorR)**2) + ((CurrentA - PriorA)**2))
          sIndex += 1
        
        # ASSERT we are at the point in the curve where we guess the point should be
        Coords = [CurrentR, CurrentA, CurrentS]
        Node.AddFiducialFromArray(Coords)
    """

  def ComputeFitRMS(self, Data, Polynomial):
    SumSquaredError = 0
    for Datum in Data:
      SumSquaredError += (Polynomial(Datum[0]) - Datum[1]) ** 2
    MeanSquarredError = SumSquaredError / len(Data)
    RMS = np.sqrt(MeanSquarredError)
    return RMS
    
  def PredictOmissionsFromFrequencyFit(self, IntervalData, PolynomialFit, FrequencyPolynomialErrors):
    OmissionPredictions = np.zeros(len(FrequencyPolynomialErrors))      # Will contain count for each interval indicating how many points seem mising
    MeanFitError = np.mean(FrequencyPolynomialErrors)        # Should be about 0, because of +/- distribution
    FitErrorStd = np.std(FrequencyPolynomialErrors)
    
    FrequencyFitRMS = self.ComputeFitRMS(IntervalData, PolynomialFit)
    #for IntervalFitError in FrequencyPolynomialErrors:
      
    
  def CombineRepairedSides(self):
    LeftPoints = [self.LeftMarkupsNode.GetMarkupPointVector(i,0) for i in range(self.LeftMarkupsNode.GetNumberOfFiducials())]
    RightPoints = [self.RightMarkupsNode.GetMarkupPointVector(i,0) for i in range(self.RightMarkupsNode.GetNumberOfFiducials())]
    AllPoints = LeftPoints + RightPoints
    AllPointsSorted = sorted(AllPoints, key=lambda Coords: Coords[2])
    AllPointsSorted.reverse()
    
    RepairedNode = slicer.vtkMRMLMarkupsFiducialNode()
    RepairedNode.SetName('RepairedLandmarks')
    
    for Landmark in AllPointsSorted:
      RepairedNode.AddFiducialFromArray(Landmark)
    
    if slicer.util.getNode(RepairedNode.GetName()) != None:
      slicer.mrmlScene.RemoveNode(slicer.util.getNode(RepairedNode.GetName()))
    slicer.mrmlScene.AddNode(RepairedNode)
    
  def RepairNode(self):
    self.ClassifyLeftRight()
    
    (LeftSrPolynomial, LeftSaPolynomial) = self.PolyFit(self.LeftMarkupsNode)
    (RightSrPolynomial, RightSaPolynomial) = self.PolyFit(self.RightMarkupsNode)
    
    (LeftIntervalData, LeftCurveFrequencyPolynomial, LeftFrequencyFitErrors) = self.CurvewiseFrequencyAnalysis(self.LeftMarkupsNode, (LeftSrPolynomial, LeftSaPolynomial), Plot=True)
    (RightIntervalData, RightFrequencyPolynomial, RightFrequencyFitErrors) = self.CurvewiseFrequencyAnalysis(self.RightMarkupsNode, (RightSrPolynomial, RightSaPolynomial))
    
    self.PredictOmissionsFromFrequencyFit(LeftIntervalData, LeftCurveFrequencyPolynomial, LeftFrequencyFitErrors)
    
    self.CombineRepairedSides()


class PreProcessLandmarksTest(ScriptedLoadableModuleTest):
  """
  This is the test case for your scripted module.
  Uses ScriptedLoadableModuleTest base class, available at:
  https://github.com/Slicer/Slicer/blob/master/Base/Python/slicer/ScriptedLoadableModule.py
  """

  def setUp(self):
    """ Do whatever is needed to reset the state - typically a scene clear will be enough.
    """
    slicer.mrmlScene.Clear(0)

  def runTest(self):
    """Run as few or as many tests as needed here.
    """
    self.setUp()
    self.test_PreProcessLandmarks1()

  def test_PreProcessLandmarks1(self):
    """ Ideally you should have several levels of tests.  At the lowest level
    tests should exercise the functionality of the logic with different inputs
    (both valid and invalid).  At higher levels your tests should emulate the
    way the user would interact with your code and confirm that it still works
    the way you intended.
    One of the most important features of the tests is that it should alert other
    developers when their changes will have an impact on the behavior of your
    module.  For example, if a developer removes a feature that you depend on,
    your test should break so they know that the feature is needed.
    """

    self.delayDisplay("Starting the test")
    #
    # first, get some data
    #
    import urllib
    downloads = (
        ('http://slicer.kitware.com/midas3/download?items=5767', 'FA.nrrd', slicer.util.loadVolume),
        )

    for url,name,loader in downloads:
      filePath = slicer.app.temporaryPath + '/' + name
      if not os.path.exists(filePath) or os.stat(filePath).st_size == 0:
        logging.info('Requesting download %s from %s...\n' % (name, url))
        urllib.urlretrieve(url, filePath)
      if loader:
        logging.info('Loading %s...' % (name,))
        loader(filePath)
    self.delayDisplay('Finished with download and loading')

    volumeNode = slicer.util.getNode(pattern="FA")
    logic = PreProcessLandmarksLogic()
    self.assertIsNotNone( logic.hasImageData(volumeNode) )
    self.delayDisplay('Test passed!')
